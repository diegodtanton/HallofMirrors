# Concatenated Project Files

```
Project Structure:
=================
├── downloaded_results
│   └── 2025-11-28_18-21-38
│       ├── mirrors
│       │   ├── checkpoints
│       │   │   ├── hs1024_l1
│       │   │   │   ├── ckpt_step_2000544.pt
│       │   │   │   ├── ckpt_step_2500256.pt
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4000544.pt
│       │   │   │   ├── ckpt_step_4500256.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6000544.pt
│       │   │   │   ├── ckpt_step_6500256.pt
│       │   │   │   ├── ckpt_step_7002016.pt
│       │   │   │   └── ckpt_step_7501728.pt
│       │   │   ├── hs1024_l2
│       │   │   │   ├── ckpt_step_2000544.pt
│       │   │   │   ├── ckpt_step_2500256.pt
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4000544.pt
│       │   │   │   ├── ckpt_step_4500256.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6000544.pt
│       │   │   │   └── ckpt_step_6500256.pt
│       │   │   ├── hs1024_l3
│       │   │   │   ├── ckpt_step_3000320.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   └── ckpt_step_5000864.pt
│       │   │   ├── hs128_l1
│       │   │   │   ├── ckpt_step_3000320.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs128_l2
│       │   │   │   ├── ckpt_step_3000320.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs128_l3
│       │   │   │   ├── ckpt_step_3000320.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs16_l1
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs16_l2
│       │   │   │   ├── ckpt_step_10000288.pt
│       │   │   │   ├── ckpt_step_10500000.pt
│       │   │   │   ├── ckpt_step_11001760.pt
│       │   │   │   ├── ckpt_step_5001216.pt
│       │   │   │   ├── ckpt_step_5500576.pt
│       │   │   │   ├── ckpt_step_6000288.pt
│       │   │   │   ├── ckpt_step_6500000.pt
│       │   │   │   ├── ckpt_step_7001760.pt
│       │   │   │   ├── ckpt_step_7500576.pt
│       │   │   │   ├── ckpt_step_8000288.pt
│       │   │   │   ├── ckpt_step_8500000.pt
│       │   │   │   ├── ckpt_step_9001760.pt
│       │   │   │   └── ckpt_step_9500576.pt
│       │   │   ├── hs16_l3
│       │   │   │   ├── ckpt_step_10000288.pt
│       │   │   │   ├── ckpt_step_10500000.pt
│       │   │   │   ├── ckpt_step_11001760.pt
│       │   │   │   ├── ckpt_step_5500576.pt
│       │   │   │   ├── ckpt_step_6000288.pt
│       │   │   │   ├── ckpt_step_6500000.pt
│       │   │   │   ├── ckpt_step_7001760.pt
│       │   │   │   ├── ckpt_step_7500576.pt
│       │   │   │   ├── ckpt_step_8000288.pt
│       │   │   │   ├── ckpt_step_8500000.pt
│       │   │   │   ├── ckpt_step_9001760.pt
│       │   │   │   └── ckpt_step_9500576.pt
│       │   │   ├── hs256_l1
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7002016.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   └── ckpt_step_8501152.pt
│       │   │   ├── hs256_l2
│       │   │   │   ├── ckpt_step_2500256.pt
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4500256.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6500256.pt
│       │   │   │   ├── ckpt_step_7002016.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   └── ckpt_step_8001440.pt
│       │   │   ├── hs256_l3
│       │   │   │   ├── ckpt_step_3000320.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs32_l1
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs32_l2
│       │   │   │   ├── ckpt_step_10000288.pt
│       │   │   │   ├── ckpt_step_4001792.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5500576.pt
│       │   │   │   ├── ckpt_step_6000288.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7500576.pt
│       │   │   │   ├── ckpt_step_8000288.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   ├── ckpt_step_9000864.pt
│       │   │   │   └── ckpt_step_9500576.pt
│       │   │   ├── hs32_l3
│       │   │   │   ├── ckpt_step_10000288.pt
│       │   │   │   ├── ckpt_step_10500000.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5500576.pt
│       │   │   │   ├── ckpt_step_6000288.pt
│       │   │   │   ├── ckpt_step_6500000.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7500576.pt
│       │   │   │   ├── ckpt_step_8000288.pt
│       │   │   │   ├── ckpt_step_8500000.pt
│       │   │   │   ├── ckpt_step_9000864.pt
│       │   │   │   └── ckpt_step_9500576.pt
│       │   │   ├── hs512_l1
│       │   │   │   ├── ckpt_step_2500256.pt
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4500256.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6500256.pt
│       │   │   │   ├── ckpt_step_7002016.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   └── ckpt_step_8001440.pt
│       │   │   ├── hs512_l2
│       │   │   │   ├── ckpt_step_2500256.pt
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4500256.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6500256.pt
│       │   │   │   ├── ckpt_step_7002016.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   └── ckpt_step_8001440.pt
│       │   │   ├── hs512_l3
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5500576.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7500576.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs64_l1
│       │   │   │   ├── ckpt_step_2500608.pt
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7002016.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   └── ckpt_step_8501152.pt
│       │   │   ├── hs64_l2
│       │   │   │   ├── ckpt_step_2500608.pt
│       │   │   │   ├── ckpt_step_3002016.pt
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5002016.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7002016.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   └── ckpt_step_8501152.pt
│       │   │   ├── hs64_l3
│       │   │   │   ├── ckpt_step_3501728.pt
│       │   │   │   ├── ckpt_step_4001440.pt
│       │   │   │   ├── ckpt_step_4501152.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5501728.pt
│       │   │   │   ├── ckpt_step_6001440.pt
│       │   │   │   ├── ckpt_step_6501152.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7501728.pt
│       │   │   │   ├── ckpt_step_8001440.pt
│       │   │   │   ├── ckpt_step_8501152.pt
│       │   │   │   └── ckpt_step_9000864.pt
│       │   │   ├── hs8_l2
│       │   │   │   ├── ckpt_step_10000288.pt
│       │   │   │   ├── ckpt_step_10500000.pt
│       │   │   │   ├── ckpt_step_4501504.pt
│       │   │   │   ├── ckpt_step_5000864.pt
│       │   │   │   ├── ckpt_step_5500576.pt
│       │   │   │   ├── ckpt_step_6000288.pt
│       │   │   │   ├── ckpt_step_6500000.pt
│       │   │   │   ├── ckpt_step_7000864.pt
│       │   │   │   ├── ckpt_step_7500576.pt
│       │   │   │   ├── ckpt_step_8000288.pt
│       │   │   │   ├── ckpt_step_8500000.pt
│       │   │   │   ├── ckpt_step_9000864.pt
│       │   │   │   └── ckpt_step_9500576.pt
│       │   │   └── hs8_l3
│       │   │       ├── ckpt_step_10000288.pt
│       │   │       ├── ckpt_step_10500000.pt
│       │   │       ├── ckpt_step_11001760.pt
│       │   │       ├── ckpt_step_5500576.pt
│       │   │       ├── ckpt_step_6000288.pt
│       │   │       ├── ckpt_step_6500000.pt
│       │   │       ├── ckpt_step_7001760.pt
│       │   │       ├── ckpt_step_7500576.pt
│       │   │       ├── ckpt_step_8000288.pt
│       │   │       ├── ckpt_step_8500000.pt
│       │   │       ├── ckpt_step_9001760.pt
│       │   │       └── ckpt_step_9500576.pt
│       │   └── data
│       │       ├── gauge_analysis_stages_hs1024_l1.csv
│       │       ├── gauge_analysis_stages_hs1024_l2.csv
│       │       ├── gauge_analysis_stages_hs1024_l3.csv
│       │       ├── gauge_analysis_stages_hs128_l1.csv
│       │       ├── gauge_analysis_stages_hs128_l2.csv
│       │       ├── gauge_analysis_stages_hs128_l3.csv
│       │       ├── gauge_analysis_stages_hs16_l1.csv
│       │       ├── gauge_analysis_stages_hs16_l2.csv
│       │       ├── gauge_analysis_stages_hs16_l3.csv
│       │       ├── gauge_analysis_stages_hs256_l1.csv
│       │       ├── gauge_analysis_stages_hs256_l2.csv
│       │       ├── gauge_analysis_stages_hs256_l3.csv
│       │       ├── gauge_analysis_stages_hs32_l1.csv
│       │       ├── gauge_analysis_stages_hs32_l2.csv
│       │       ├── gauge_analysis_stages_hs32_l3.csv
│       │       ├── gauge_analysis_stages_hs512_l1.csv
│       │       ├── gauge_analysis_stages_hs512_l2.csv
│       │       ├── gauge_analysis_stages_hs512_l3.csv
│       │       ├── gauge_analysis_stages_hs64_l1.csv
│       │       ├── gauge_analysis_stages_hs64_l2.csv
│       │       ├── gauge_analysis_stages_hs64_l3.csv
│       │       ├── gauge_analysis_stages_hs8_l2.csv
│       │       ├── gauge_analysis_stages_hs8_l3.csv
│       │       ├── hs1024_l1_grace_progress.csv
│       │       ├── hs1024_l1_hall_progress.csv
│       │       ├── hs1024_l2_grace_progress.csv
│       │       ├── hs1024_l3_grace_progress.csv
│       │       ├── hs128_l1_grace_progress.csv
│       │       ├── hs128_l1_hall_progress.csv
│       │       ├── hs128_l2_grace_progress.csv
│       │       ├── hs128_l2_hall_progress.csv
│       │       ├── hs128_l3_grace_progress.csv
│       │       ├── hs128_l3_hall_progress.csv
│       │       ├── hs16_l1_grace_progress.csv
│       │       ├── hs16_l1_hall_progress.csv
│       │       ├── hs16_l2_grace_progress.csv
│       │       ├── hs16_l2_hall_progress.csv
│       │       ├── hs16_l3_grace_progress.csv
│       │       ├── hs16_l3_hall_progress.csv
│       │       ├── hs256_l1_grace_progress.csv
│       │       ├── hs256_l1_hall_progress.csv
│       │       ├── hs256_l2_grace_progress.csv
│       │       ├── hs256_l2_hall_progress.csv
│       │       ├── hs256_l3_grace_progress.csv
│       │       ├── hs256_l3_hall_progress.csv
│       │       ├── hs32_l1_grace_progress.csv
│       │       ├── hs32_l1_hall_progress.csv
│       │       ├── hs32_l2_grace_progress.csv
│       │       ├── hs32_l2_hall_progress.csv
│       │       ├── hs32_l3_grace_progress.csv
│       │       ├── hs32_l3_hall_progress.csv
│       │       ├── hs512_l1_grace_progress.csv
│       │       ├── hs512_l1_hall_progress.csv
│       │       ├── hs512_l2_grace_progress.csv
│       │       ├── hs512_l2_hall_progress.csv
│       │       ├── hs512_l3_grace_progress.csv
│       │       ├── hs64_l1_grace_progress.csv
│       │       ├── hs64_l1_hall_progress.csv
│       │       ├── hs64_l2_grace_progress.csv
│       │       ├── hs64_l2_hall_progress.csv
│       │       ├── hs64_l3_grace_progress.csv
│       │       ├── hs64_l3_hall_progress.csv
│       │       ├── hs8_l2_grace_progress.csv
│       │       ├── hs8_l2_hall_progress.csv
│       │       ├── hs8_l3_grace_progress.csv
│       │       ├── hs8_l3_hall_progress.csv
│       │       ├── mirrors_summary_hs1024_l1.csv
│       │       ├── mirrors_summary_hs128_l1.csv
│       │       ├── mirrors_summary_hs128_l2.csv
│       │       ├── mirrors_summary_hs128_l3.csv
│       │       ├── mirrors_summary_hs16_l1.csv
│       │       ├── mirrors_summary_hs16_l2.csv
│       │       ├── mirrors_summary_hs16_l3.csv
│       │       ├── mirrors_summary_hs256_l1.csv
│       │       ├── mirrors_summary_hs256_l2.csv
│       │       ├── mirrors_summary_hs256_l3.csv
│       │       ├── mirrors_summary_hs32_l1.csv
│       │       ├── mirrors_summary_hs32_l2.csv
│       │       ├── mirrors_summary_hs32_l3.csv
│       │       ├── mirrors_summary_hs512_l1.csv
│       │       ├── mirrors_summary_hs512_l2.csv
│       │       ├── mirrors_summary_hs64_l1.csv
│       │       ├── mirrors_summary_hs64_l2.csv
│       │       ├── mirrors_summary_hs64_l3.csv
│       │       ├── mirrors_summary_hs8_l2.csv
│       │       └── mirrors_summary_hs8_l3.csv
│       └── pretrain
│           ├── checkpoints
│           │   ├── hs1024_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs1024_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs1024_l3
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs128_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs128_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs128_l3
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs16_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs16_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_3500032.pt
│           │   │   ├── ckpt_step_4001792.pt
│           │   │   ├── ckpt_step_4501504.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs16_l3
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_3500032.pt
│           │   │   ├── ckpt_step_4001792.pt
│           │   │   ├── ckpt_step_4501504.pt
│           │   │   ├── ckpt_step_5001216.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs256_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs256_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs256_l3
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs32_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs32_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_3500032.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs32_l3
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_3500032.pt
│           │   │   ├── ckpt_step_4001792.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs512_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs512_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs512_l3
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_3500032.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs64_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs64_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs64_l3
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   ├── hs8_l1
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_3500032.pt
│           │   │   ├── ckpt_step_4001792.pt
│           │   │   ├── ckpt_step_4501504.pt
│           │   │   ├── ckpt_step_5001216.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── ckpt_step_5500928.pt
│           │   │   ├── ckpt_step_6000000.pt
│           │   │   └── training_progress.png
│           │   ├── hs8_l2
│           │   │   ├── ckpt_step_1001472.pt
│           │   │   ├── ckpt_step_1501184.pt
│           │   │   ├── ckpt_step_2000896.pt
│           │   │   ├── ckpt_step_2500608.pt
│           │   │   ├── ckpt_step_3000320.pt
│           │   │   ├── ckpt_step_3500032.pt
│           │   │   ├── ckpt_step_4001792.pt
│           │   │   ├── ckpt_step_501760.pt
│           │   │   ├── final_solved.pt
│           │   │   └── training_progress.png
│           │   └── hs8_l3
│           │       ├── ckpt_step_1001472.pt
│           │       ├── ckpt_step_1501184.pt
│           │       ├── ckpt_step_2000896.pt
│           │       ├── ckpt_step_2500608.pt
│           │       ├── ckpt_step_3000320.pt
│           │       ├── ckpt_step_3500032.pt
│           │       ├── ckpt_step_4001792.pt
│           │       ├── ckpt_step_4501504.pt
│           │       ├── ckpt_step_5001216.pt
│           │       ├── ckpt_step_501760.pt
│           │       ├── final_solved.pt
│           │       └── training_progress.png
│           └── data
│               ├── gauge_analysis_hs1024_l1.csv
│               ├── gauge_analysis_hs1024_l2.csv
│               ├── gauge_analysis_hs1024_l3.csv
│               ├── gauge_analysis_hs128_l1.csv
│               ├── gauge_analysis_hs128_l2.csv
│               ├── gauge_analysis_hs128_l3.csv
│               ├── gauge_analysis_hs16_l1.csv
│               ├── gauge_analysis_hs16_l2.csv
│               ├── gauge_analysis_hs16_l3.csv
│               ├── gauge_analysis_hs256_l1.csv
│               ├── gauge_analysis_hs256_l2.csv
│               ├── gauge_analysis_hs256_l3.csv
│               ├── gauge_analysis_hs32_l1.csv
│               ├── gauge_analysis_hs32_l2.csv
│               ├── gauge_analysis_hs32_l3.csv
│               ├── gauge_analysis_hs512_l1.csv
│               ├── gauge_analysis_hs512_l2.csv
│               ├── gauge_analysis_hs512_l3.csv
│               ├── gauge_analysis_hs64_l1.csv
│               ├── gauge_analysis_hs64_l2.csv
│               ├── gauge_analysis_hs64_l3.csv
│               ├── gauge_analysis_hs8_l1.csv
│               ├── gauge_analysis_hs8_l2.csv
│               ├── gauge_analysis_hs8_l3.csv
│               ├── hs1024_l1_progress.csv
│               ├── hs1024_l2_progress.csv
│               ├── hs1024_l3_progress.csv
│               ├── hs128_l1_progress.csv
│               ├── hs128_l2_progress.csv
│               ├── hs128_l3_progress.csv
│               ├── hs16_l1_progress.csv
│               ├── hs16_l2_progress.csv
│               ├── hs16_l3_progress.csv
│               ├── hs256_l1_progress.csv
│               ├── hs256_l2_progress.csv
│               ├── hs256_l3_progress.csv
│               ├── hs32_l1_progress.csv
│               ├── hs32_l2_progress.csv
│               ├── hs32_l3_progress.csv
│               ├── hs512_l1_progress.csv
│               ├── hs512_l2_progress.csv
│               ├── hs512_l3_progress.csv
│               ├── hs64_l1_progress.csv
│               ├── hs64_l2_progress.csv
│               ├── hs64_l3_progress.csv
│               ├── hs8_l1_progress.csv
│               ├── hs8_l2_progress.csv
│               └── hs8_l3_progress.csv
├── launch_parallel.sh
├── mirrors
│   ├── checkpoints
│   │   └── hs16_l2
│   │       ├── ckpt_step_40720.pt
│   │       ├── ckpt_step_60720.pt
│   │       └── ckpt_step_80720.pt
│   ├── data
│   │   ├── hs16_l2_grace_progress.csv
│   │   ├── hs16_l2_hall_progress.csv
│   │   └── mirrors_summary_hs16_l2.csv
│   ├── gauges.py
│   └── main.py
├── overview.md
├── pretrain
│   ├── checkpoints
│   │   └── hs16_l2
│   │       ├── final_solved.pt
│   │       └── training_progress.png
│   ├── data
│   │   ├── gauge_analysis_hs16_l2.csv
│   │   └── hs16_l2_progress.csv
│   ├── gauges.py
│   └── main.py
├── requirements.txt
├── run_pipeline.py
├── shared
│   ├── agent.py
│   ├── config.py
│   ├── env.py
│   └── model.py
└── utils
    ├── clean.py
    ├── concat.md
    ├── concat.py
    ├── gcp
    │   ├── config.py
    │   ├── connect.py
    │   ├── pull_data.py
    │   ├── push_code.py
    │   ├── view.py
    │   └── vm_steps.txt
    └── plot_story.py
=================

```

## File: launch_parallel.sh

```sh
#!/bin/bash

# ========================================================
# Parallel Launcher for Hall of Mirrors Experiment
# ========================================================

# 1. FORCE SINGLE-THREADED MODE
# This prevents PyTorch from spawning 32 threads per process
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
export VECLIB_MAXIMUM_THREADS=1
export NUMEXPR_NUM_THREADS=1
export TORCH_NUM_THREADS=1

# Create log directory
mkdir -p logs

echo "Starting 12 parallel experiments..."
echo "Configured for Single-Threaded PyTorch (prevents CPU thrashing)"

# List of configurations: "HiddenSize Layers"
configs=(
    "8 1" "16 1" "32 1" "64 1" "128 1" "256 1" "512 1" "1024 1"
    "8 2" "16 2" "32 2" "64 2" "128 2" "256 2" "512 2" "1024 2"
    "8 3" "16 3" "32 3" "64 3" "128 3" "256 3" "512 3" "1024 3"
)

for config in "${configs[@]}"; do
    # Split the string into variables
    set -- $config
    hs=$1
    layers=$2
    
    run_id="hs${hs}_l${layers}"
    echo "Launching process for: $run_id"
    
    # Run in background (&), redirect stdout and stderr to a log file
    # We use nohup so it survives if your SSH session disconnects
    nohup python3 run_pipeline.py --hs $hs --layers $layers > "logs/${run_id}.log" 2>&1 &
    
    # Sleep briefly to stagger startups
    sleep 1
done

echo "========================================================"
echo "All jobs launched in background."
echo "Check progress using 'htop' (Load avg should be ~12-15)"
echo "========================================================"
```

## File: mirrors\gauges.py

```py
# ============================================
# File: mirrors/gauges.py
# ============================================

import glob
import os
import torch
import pandas as pd
from shared.config import (
    COMPLEXITIES, GRACE_STEPS,
    PRETRAIN_CHECKPOINT_DIR, MIRRORS_CHECKPOINT_DIR, MIRRORS_DATA_DIR
)
from shared.env import HallOfMirrorsGridworld, ManualFrameStack
from shared.agent import PPOAgent
from pretrain.gauges import collect_gauge_dataset, compute_metrics

STAGE_DURATION = 2_000_000

def get_step_from_filename(filepath):
    """Extracts 12345 from '.../ckpt_step_12345.pt'"""
    base = os.path.basename(filepath)
    if not base.startswith("ckpt_step_"): return -1
    try:
        return int(base.replace("ckpt_step_", "").replace(".pt", ""))
    except:
        return -1

def find_stage_checkpoints(run_name, hs, nl):
    """
    Calculates the step boundaries for this specific run and finds
    the closest existing checkpoint for each stage end.
    """
    # 1. Determine T_0 (End of Pretraining)
    pre_dir = os.path.join(PRETRAIN_CHECKPOINT_DIR, run_name)
    final_ckpt = os.path.join(pre_dir, "final_solved.pt")
    
    start_steps = 0
    if os.path.exists(final_ckpt):
        # Load lightweight to get steps
        state = torch.load(final_ckpt, map_location='cpu', weights_only=False)
        start_steps = state.get("total_env_steps", 0)
    else:
        # Fallback: find latest numbered ckpt in pretrain
        all_pre = glob.glob(os.path.join(pre_dir, "ckpt_step_*.pt"))
        if not all_pre:
            print(f"  Warning: No pretrain start found for {run_name}")
            return {}
        latest = max(all_pre, key=get_step_from_filename)
        start_steps = get_step_from_filename(latest)

    # 2. Define Targets
    # T_0 + Grace + Stage 1
    target_s1 = start_steps + GRACE_STEPS + STAGE_DURATION
    # Target 1 + Stage 2
    target_s2 = target_s1 + STAGE_DURATION
    # Target 2 + Stage 3
    target_s3 = target_s2 + STAGE_DURATION

    targets = {
        "stage_1_rot": target_s1,
        "stage_2_step": target_s2,
        "stage_3_val": target_s3
    }

    # 3. Find Closest Mirrors Checkpoints
    mir_dir = os.path.join(MIRRORS_CHECKPOINT_DIR, run_name)
    all_mirrors = glob.glob(os.path.join(mir_dir, "ckpt_step_*.pt"))
    
    if not all_mirrors:
        return {}

    # Map {step: path}
    step_map = {get_step_from_filename(p): p for p in all_mirrors if get_step_from_filename(p) > 0}
    if not step_map: return {}
    
    available_steps = list(step_map.keys())
    
    found_checkpoints = {}
    
    for stage_name, target_step in targets.items():
        # Find closest step
        closest_step = min(available_steps, key=lambda x: abs(x - target_step))
        distance = abs(closest_step - target_step)
        
        # Sanity Check: If the closest checkpoint is > 1M steps away, 
        # the run probably crashed or hasn't reached that stage yet.
        if distance > 1_000_000:
            print(f"  Skipping {stage_name}: Closest ckpt is {distance} steps away (incomplete run?)")
            continue
            
        found_checkpoints[stage_name] = step_map[closest_step]
        print(f"  Map {stage_name}: Target {target_step} -> Found {closest_step} (Diff: {distance})")

    return found_checkpoints


def run_post_mirrors_analysis(target_configs=None):
    if target_configs is None:
        target_configs = COMPLEXITIES

    print(f"Searching for checkpoints in {MIRRORS_CHECKPOINT_DIR}...")
    gauge_types = ["rotation", "step_size", "reward_map", "nuisance", "dist_to_wall"]

    for (hs, nl) in target_configs:
        run_name = f"hs{hs}_l{nl}"
        
        # Use the math logic to find files
        stage_map = find_stage_checkpoints(run_name, hs, nl)
        
        if not stage_map:
            print(f"Skipping {run_name} (no valid stage checkpoints found)")
            continue

        print(f"\n=== Analyzing {run_name} Stages ===")
        
        stage_results = []

        for stage_name, ckpt_path in stage_map.items():
            print(f"  > Analyzing {stage_name}...")
            
            # Load Agent
            # Note: We use Fixed env for analysis regardless of training stage
            base_env = HallOfMirrorsGridworld(random_rot=False, random_step=False, random_val=False)
            env = ManualFrameStack(base_env)
            agent = PPOAgent(env, hidden_size=hs, n_hidden_layers=nl)
            agent.load_checkpoint(ckpt_path)

            # Collect Data
            records = collect_gauge_dataset(agent)

            for g_type in gauge_types:
                sens, dec, morph = compute_metrics(records, g_type)
                stage_results.append({
                    "hidden_size": hs,
                    "num_layers": nl,
                    "stage": stage_name,
                    "gauge_type": g_type,
                    "sensitivity": sens,
                    "decodability": dec,
                    "morphism": morph,
                })

        # Save Result
        if stage_results:
            outfile = os.path.join(MIRRORS_DATA_DIR, f"gauge_analysis_stages_{run_name}.csv")
            pd.DataFrame(stage_results).to_csv(outfile, index=False)
            print(f"Saved stage analysis to {outfile}")

if __name__ == "__main__":
    run_post_mirrors_analysis()
```

## File: mirrors\main.py

```py
# ============================================
# File: mirrors/main.py
# ============================================

import argparse
import glob
import os

import matplotlib.pyplot as plt
import pandas as pd

from shared.config import (
    COMPLEXITIES,
    GRACE_STEPS,
    PRETRAIN_CHECKPOINT_DIR,
    MIRRORS_CHECKPOINT_DIR,
    MIRRORS_DATA_DIR,
    STAGE_BUDGET,
    HALL_STEPS
)
from shared.env import HallOfMirrorsGridworld, ManualFrameStack
from shared.agent import PPOAgent, PPOConfig, evaluate_agent


def run_batch_mirrors(include_unsolved: bool = False, target_configs=None):
    if target_configs is None:
        target_configs = COMPLEXITIES

    for (hs, nl) in target_configs:
        run_name = f"hs{hs}_l{nl}"
        print(f"\n=== Mirrors Adaptation for {run_name} ===")

        pretrain_dir = os.path.join(PRETRAIN_CHECKPOINT_DIR, run_name)
        if not os.path.isdir(pretrain_dir):
            print(f"  Skipping {run_name} (no pretrain dir)")
            continue

        ckpts = glob.glob(os.path.join(pretrain_dir, "*.pt"))
        if not ckpts:
            print(f"  Skipping {run_name} (no pretrain checkpoints)")
            continue

        final_ckpt = os.path.join(pretrain_dir, "final_solved.pt")
        solved = os.path.exists(final_ckpt)

        if solved:
            ckpt_path = final_ckpt
        else:
            if not include_unsolved:
                print(f"  Skipping {run_name} (unsolved and include_unsolved=False)")
                continue
            ckpt_path = max(ckpts, key=os.path.getctime)

        print(f"  Using checkpoint: {ckpt_path} (solved={solved})")

        # Setup Env
        base_env = HallOfMirrorsGridworld(
            random_rot=False, random_step=False, random_val=False
        )
        env = ManualFrameStack(base_env)
        
        # Increase Total Steps to 6M (2M + 2M + 2M)
        # Note: 'total_steps' in config is the *limit*. 
        # The agent.train() loop continues from agent.total_env_steps.
        
        cfg = PPOConfig(total_steps=HALL_STEPS) # Placeholder, updated per phase
        agent = PPOAgent(env, hidden_size=hs, n_hidden_layers=nl, config=cfg)
        agent.load_checkpoint(ckpt_path)

        adapt_ckpt_dir = os.path.join(MIRRORS_CHECKPOINT_DIR, run_name)
        os.makedirs(adapt_ckpt_dir, exist_ok=True)

        all_stats = []

        def make_plot_cb():
            def _plot_cb(stats):
                if not stats: return
                df = pd.DataFrame(stats)
                # Append current stats to global tracking if needed, or just save csv
                csv_path = os.path.join(MIRRORS_DATA_DIR, f"{run_name}_hall_progress.csv")
                
                # If file exists, append? No, 'stats' grows accumulatively in agent.train
                # actually agent.train returns the *new* stats from that call.
                # To keep it simple, we just overwrite the CSV with the cumulative stats 
                # from the current train call, but that misses previous stages.
                # Better: let's rely on agent.total_env_steps to be consistent.
                
                # We will just append new data to the CSV manually after each stage.
                pass
            return _plot_cb

        # 1. Pre Evaluation
        pre_return = evaluate_agent(agent, env, n_episodes=30)
        print(f"  [Pre] avg return: {pre_return:.2f}")

        # 2. Grace Period
        print(f"  Running grace phase for {GRACE_STEPS} steps...")
        agent.config.total_steps = agent.total_env_steps + GRACE_STEPS
        stats_grace = agent.train(
            verbose=False, stop_at_return=None, checkpoint_dir=adapt_ckpt_dir
        )
        # Save Grace CSV
        pd.DataFrame(stats_grace).to_csv(
            os.path.join(MIRRORS_DATA_DIR, f"{run_name}_grace_progress.csv"), index=False
        )
        grace_return = evaluate_agent(agent, env, n_episodes=30)
        print(f"  [After grace] avg return: {grace_return:.2f}")

        # ----------------------------------------------------
        # STAGE 1: Random Rotation (Step & Val Fixed)
        # ----------------------------------------------------
        print(f"  [Stage 1] Random Rotation ({STAGE_BUDGET} Steps)...")
        base_env.random_rot = True
        base_env.random_step = False
        base_env.random_val = False
        
        agent.config.total_steps = agent.total_env_steps + STAGE_BUDGET
        stats_s1 = agent.train(verbose=True, checkpoint_dir=adapt_ckpt_dir)
        
        # ----------------------------------------------------
        # STAGE 2: Random Step Size (Rot & Val Fixed)
        # ----------------------------------------------------
        print(f"  [Stage 2] Random Step Size ({STAGE_BUDGET} Steps)...")
        base_env.random_rot = False
        base_env.random_step = True
        base_env.random_val = False
        
        agent.config.total_steps = agent.total_env_steps + STAGE_BUDGET
        stats_s2 = agent.train(verbose=True, checkpoint_dir=adapt_ckpt_dir)

        # ----------------------------------------------------
        # STAGE 3: Random Value Map (Rot & Step Fixed)
        # ----------------------------------------------------
        print(f"  [Stage 3] Random Value Map ({STAGE_BUDGET} Steps)...")
        base_env.random_rot = False
        base_env.random_step = False
        base_env.random_val = True
        
        agent.config.total_steps = agent.total_env_steps + STAGE_BUDGET
        stats_s3 = agent.train(verbose=True, checkpoint_dir=adapt_ckpt_dir)

        # Combine Hall Stats
        full_hall_stats = stats_s1 + stats_s2 + stats_s3
        pd.DataFrame(full_hall_stats).to_csv(
            os.path.join(MIRRORS_DATA_DIR, f"{run_name}_hall_progress.csv"), index=False
        )
        
        # Final Eval
        hall_return = evaluate_agent(agent, env, n_episodes=50)
        print(f"  [Post-hall] avg return: {hall_return:.2f}")

        # Save result for THIS run
        result_data = [{
            "hidden_size": hs,
            "layers": nl,
            "solved_pretrain": solved,
            "pre_return": pre_return,
            "grace_return": grace_return,
            "hall_return": hall_return,
        }]
        
        outfile = os.path.join(MIRRORS_DATA_DIR, f"mirrors_summary_{run_name}.csv")
        pd.DataFrame(result_data).to_csv(outfile, index=False)
        print(f"Saved mirrors summary to {outfile}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--include-unsolved", action="store_true")
    args = parser.parse_args()
    run_batch_mirrors(include_unsolved=args.include_unsolved)
```

## File: overview.md

```md
# Experiment Overview: Subjectivity & Gauge Reification

## Big Picture

This project investigates **Subjectivity in Artificial Agents** through the lens of **Gauge Theory**. We hypothesize that as agents increase in complexity (parameter count/depth), they transition from implicitly handling interface parameters (gauges) to explicitly representing them ("reifying" them).

The experiment runs across a sweep of 24 architectures, defined in `shared/config.py`.

---

## Phase 1 – Pretraining (Fixed Interface)

**File:** `pretrain/main.py`

The agent is trained to proficiency in a static environment. This establishes a baseline where the agent learns to operate a specific "body" without needing to model it.

* **Environment:** `HallOfMirrorsGridworld` (`shared/env.py`)
    * **Gauges Fixed:** Rotation=0, Step=1, Blue=Good.
    * **Observation:** 4-Frame Stack (Walls, Red, Blue, Self, **Noise**).
    * **New Input:** Agent now receives `prev_reward` as a scalar input.
* **Budget:** `PRETRAIN_MAX_STEPS = 6_000_000`.
* **Success Criterion:** Rolling return $\ge$ `PRETRAIN_TARGET_RETURN = 12.0`.

**Outputs per `(hs, layers)`:**
* `pretrain/checkpoints/.../final_solved.pt`

---

## Phase 2 – Gauge Identification (The "Pre" Scan)

**File:** `pretrain/gauges.py`

Before the agent enters the Hall of Mirrors, we probe its internal representations ($z$) to calculate **Gauge Scores** for five specific features.

**The 5 Features:**
1.  **Rotation Gauge:** `sensor_rotation ∈ {0,1,2,3}`.
2.  **Step-size Gauge:** `step_size ∈ {1,2}`.
3.  **Reward-map Gauge:** `good_is_red ∈ {True, False}`.
4.  **Nuisance (Control):** Random visual noise pattern (Channel 5). *Tests if agent is distracted by irrelevant pixels.*
5.  **Explicit Feature (Target):** Distance to nearest wall. *Tests what a "useful, understood" feature looks like.*

**The Metrics (S / D / M):**
* **Sensitivity (S):** Does $z$ change when the feature changes (holding geometry constant)?
* **Decodability (D):** Can a linear probe predict the feature value from $z$?
* **Morphism (M):** Is the transformation $z_{val1} \to z_{val2}$ linear/geometric?

**The Gauge Score:**
$$\text{Score} = \text{Sensitivity} \times \text{Morphism} \times (1 - \text{Decodability})$$
*High score = Hidden Gauge (Implicit).*
*Low score (due to high D) = Reified Feature (Explicit).*

---

## Phase 3 – Hall-of-Mirrors Adaptation (Curriculum)

**File:** `mirrors/main.py`

We take the pretrained agent and force it to adapt to a changing interface. The "Hall of Mirrors" is broken into three distinct stages to test each gauge independently.

**Total Budget:** `HALL_STEPS = 6_000_000` (plus `10_000` grace steps).

1.  **Grace Period:** Small window with fixed gauges to establish stability.
2.  **Stage 1 (Rotation):** 2M Steps. Rotation varies randomly per episode. Step/Value fixed.
    * *Save:* `ckpt_stage_1_rot.pt`
3.  **Stage 2 (Step Size):** 2M Steps. Step size varies randomly. Rotation/Value fixed.
    * *Save:* `ckpt_stage_2_step.pt`
4.  **Stage 3 (Value Map):** 2M Steps. Red/Blue meaning varies randomly. Rotation/Step fixed.
    * *Save:* `ckpt_stage_3_val.pt`

---

## Phase 4 – Analysis & Story Figures

**Files:** `mirrors/gauges.py` & `utils/plot_story.py`

We analyze the checkpoints from Phase 3 to see if the Gauge Scores have dropped (indicating Reification).

### Fig 1: Baseline Gauge Identification
* **Visual:** Boxplot overlaid with Strip Plot (Scatter).
* **X-axis:** The 5 Features (Dist, Nuisance, Rotation, Step, Reward).
* **Y-axis:** Gauge Score (Pre-training).
* **Color:** Dots colored by Agent Complexity (Parameter Count).
* **Goal:** Validate that Pre-trained agents treat Rotation/Step/Reward as **Hidden Gauges** (High Score), while Nuisance and Explicit features have Low Scores.

### Fig 2: Performance Timeline (Example Agent)
* **Visual:** Time-series line plot for a representative agent (e.g., `hs64_l2`).
* **X-axis:** Total Steps.
* **Y-axis:** Rolling Return.
* **Regions:** Shaded backgrounds for Pretrain, Grace, and Hall Stages.
* **Goal:** Show the "drop" in performance when the mirrors turn on, and the subsequent recovery.

### Fig 3: Recovery & Reification vs. Complexity
A 3x2 Grid visualizing the core hypothesis.

**Rows:**
1.  **Rotation Phase**
2.  **Step-Size Phase**
3.  **Reward-Map Phase**

**Left Column: Performance Recovery**
* **Y-axis:** Max Recovery % (Max Return in Stage / 12.0).
* **X-axis:** Complexity (Hidden Size).
* **Lines:** Grouped by Depth (1, 2, 3 layers).
* *Hypothesis:* Larger models recover better.

**Right Column: Gauge Reification**
* **Metric:** $\text{Reification} = \max(\text{Score}_{\text{Pre}} - \text{Score}_{\text{Stage\_End}}, 0)$.
* **Y-axis:** Reification Score.
* **X-axis:** Complexity (Hidden Size).
* **Lines:** Grouped by Depth.
* *Hypothesis:* Larger models show higher reification (they "solve" the gauge by making it explicit).

### Table 1: The Evolution of Subjectivity
A summary table showing the Mean $\pm$ Std Gauge Score for all 5 features across four timepoints:
1.  End of Pretraining.
2.  End of Stage 1 (Rot).
3.  End of Stage 2 (Step).
4.  End of Stage 3 (Val).

This tracks the "life story" of the agent's interface representation.
```

## File: pretrain\gauges.py

```py
# ============================================
# File: pretrain/gauges.py
# ============================================

import glob
import os
from typing import List, Dict, Any

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim

from shared.config import (
    COMPLEXITIES,
    PRETRAIN_CHECKPOINT_DIR,
    PRETRAIN_DATA_DIR,
    GRID_SIZE, MAX_STEPS_PER_EPISODE, 
    N_GOOD_TILES, N_BAD_TILES, FRAME_STACK_SIZE
)
from shared.env import HallOfMirrorsGridworld, ManualFrameStack
from shared.agent import PPOAgent

def collect_gauge_dataset(
    agent: PPOAgent, n_episodes_per_setting: int = 5, max_steps: int = 50
) -> List[Dict[str, Any]]:
    records: List[Dict[str, Any]] = []
    rng = np.random.RandomState(42)

    base_env = HallOfMirrorsGridworld(
        grid_size=GRID_SIZE,
        max_steps=MAX_STEPS_PER_EPISODE,
        n_good_tiles=N_GOOD_TILES,
        n_bad_tiles=N_BAD_TILES,
        # Fixed defaults
        random_rot=False, random_step=False, random_val=False,
        fixed_sensor_rotation=0, fixed_step_size=1, fixed_good_is_red=False,
    )
    env = ManualFrameStack(base_env, num_stack=FRAME_STACK_SIZE)

    # --- 1. Gauge Variations ---
    for layout_idx in range(n_episodes_per_setting):
        base_seed = rng.randint(0, 100000)
        
        # Pre-calculate actions
        actions = [rng.randint(0, env.action_space.n) for _ in range(max_steps)]

        # A. Rotation
        for rot in [0, 1, 2, 3]:
            base_env.reseed(base_seed)
            base_env.fixed_sensor_rotation = rot
            base_env.fixed_step_size = 1
            base_env.fixed_good_is_red = False
            
            obs, _ = env.reset()
            obs = obs.astype(np.float32)
            prev_r = 0.0
            
            for t, act in enumerate(actions):
                # Pass prev_reward to latent
                z = agent.get_latent(obs[None, ...], prev_reward_val=prev_r)[0]
                records.append({
                    "z": z, "val": rot, "layout": layout_idx, "step_id": t, "type": "rotation",
                })
                obs, reward, term, trunc, _ = env.step(act)
                obs = obs.astype(np.float32)
                prev_r = float(reward)
                if term or trunc: break

        # B. Step Size
        for step in [1, 2]:
            base_env.reseed(base_seed)
            base_env.fixed_sensor_rotation = 0
            base_env.fixed_step_size = step
            base_env.fixed_good_is_red = False
            
            obs, _ = env.reset()
            obs = obs.astype(np.float32)
            prev_r = 0.0
            
            for t, act in enumerate(actions):
                z = agent.get_latent(obs[None, ...], prev_reward_val=prev_r)[0]
                records.append({
                    "z": z, "val": step, "layout": layout_idx, "step_id": t, "type": "step_size",
                })
                obs, reward, term, trunc, _ = env.step(act)
                obs = obs.astype(np.float32)
                prev_r = float(reward)
                if term or trunc: break

        # C. Reward Map
        for is_red in [True, False]:
            base_env.reseed(base_seed)
            base_env.fixed_sensor_rotation = 0
            base_env.fixed_step_size = 1
            base_env.fixed_good_is_red = is_red
            
            obs, _ = env.reset()
            obs = obs.astype(np.float32)
            prev_r = 0.0
            
            val_int = 1 if is_red else 0
            for t, act in enumerate(actions):
                z = agent.get_latent(obs[None, ...], prev_reward_val=prev_r)[0]
                records.append({
                    "z": z, "val": val_int, "layout": layout_idx, "step_id": t, "type": "reward_map",
                })
                obs, reward, term, trunc, _ = env.step(act)
                obs = obs.astype(np.float32)
                prev_r = float(reward)
                if term or trunc: break

    # --- 2. Nuisance (Noise Channel) & Explicit Feature ---
    # We iterate over layouts first (Geometry)
    for layout_idx in range(n_episodes_per_setting):
        base_seed = rng.randint(0, 100000)
        
        # 1. Establish Geometry & Actions
        # We need to peek at the geometry to get actions, so we reset once.
        base_env.reseed(base_seed)
        base_env.reset()
        actions = [rng.randint(0, env.action_space.n) for _ in range(max_steps)]
        
        # 2. Cycle through NOISE patterns on this exact geometry
        # This keeps 'dist_to_wall' constant per step_id, but changes pixels.
        for noise_seed in [100, 200, 300, 400]:
            base_env.reseed(base_seed)
            base_env.fixed_sensor_rotation = 0
            base_env.fixed_step_size = 1
            base_env.fixed_good_is_red = False
            
            # Reset generates the first observation with default noise
            base_env.reset()
            
            # Force the specific noise pattern we want
            base_env.force_noise_pattern(noise_seed)
            
            # Refresh the frame stack manually to clear old noise
            fresh_obs = base_env._get_obs()
            env.frames.clear()
            for _ in range(FRAME_STACK_SIZE):
                env.frames.append(fresh_obs)
            obs = env._get_ob().astype(np.float32)
            
            prev_r = 0.0
            
            for t, act in enumerate(actions):
                z = agent.get_latent(obs[None, ...], prev_reward_val=prev_r)[0]
                
                # --- explicit feature calculation ---
                y, x = base_env.agent_pos
                def ray(dy, dx):
                    d = 0
                    cy, cx = y, x
                    while True:
                        cy += dy; cx += dx
                        if not (0 <= cy < base_env.grid_size and 0 <= cx < base_env.grid_size): break 
                        if base_env.grid[cy, cx] == 1: break
                        d += 1
                    return d
                
                min_dist = min(ray(-1, 0), ray(1, 0), ray(0, -1), ray(0, 1))
                
                # Record Noise Nuisance (val = noise_seed)
                records.append({
                    "z": z, "val": noise_seed, "layout": layout_idx, "step_id": t, "type": "nuisance",
                })
                
                # Record Explicit Feature (val = distance)
                records.append({
                    "z": z, "val": min_dist, "layout": layout_idx, "step_id": t, "type": "dist_to_wall", 
                })

                obs, reward, term, trunc, _ = env.step(act)
                obs = obs.astype(np.float32)
                prev_r = float(reward)
                if term or trunc: break

    return records


def compute_metrics(records: List[Dict[str, Any]], gauge_type: str):
    data = [r for r in records if r["type"] == gauge_type]
    if not data:
        return 0.0, 0.0, 0.0

    # --- 1. Sensitivity ---
    # For 'dist_to_wall', sensitivity isn't defined via intervention.
    if gauge_type == "dist_to_wall":
        sens = 0.0
    else:
        aligned_groups = {}
        for r in data:
            key = (r["layout"], r["step_id"])
            aligned_groups.setdefault(key, []).append(r["z"])
        
        dists = []
        for zs in aligned_groups.values():
            if len(zs) < 2: continue
            stack = np.stack(zs)
            mean_z = np.mean(stack, axis=0)
            dist = np.mean(np.linalg.norm(stack - mean_z, axis=1))
            dists.append(dist)
        sens = float(np.mean(dists)) if dists else 0.0

    # --- 2. Decodability ---
    X = np.stack([r["z"] for r in data])
    y_raw = np.array([r["val"] for r in data])
    unique_y, y_int = np.unique(y_raw, return_inverse=True)
    n_classes = len(unique_y)

    idx = np.arange(len(X))
    np.random.shuffle(idx)
    split = int(0.8 * len(X))
    train_idx, test_idx = idx[:split], idx[split:]
    
    X_train = torch.from_numpy(X[train_idx]).float()
    y_train = torch.from_numpy(y_int[train_idx]).long()
    X_test = torch.from_numpy(X[test_idx]).float()
    y_test = torch.from_numpy(y_int[test_idx]).long()

    if n_classes < 2:
        dec = 0.0
    else:
        probe = nn.Linear(X.shape[1], n_classes)
        opt = optim.Adam(probe.parameters(), lr=1e-2)
        loss_fn = nn.CrossEntropyLoss()
        
        for _ in range(200):
            logits = probe(X_train)
            loss = loss_fn(logits, y_train)
            opt.zero_grad()
            loss.backward()
            opt.step()
        
        with torch.no_grad():
            preds = probe(X_test).argmax(dim=-1)
            dec = float((preds == y_test).float().mean().item())

    # --- 3. Morphism ---
    # Only calculate morphism for true gauges, not explicit/nuisance
    if gauge_type in ["dist_to_wall", "nuisance"]:
        return sens, dec, 0.0

    vals = sorted(list(set(y_raw)))
    if len(vals) < 2: 
        return sens, dec, 0.0
    
    v0, v1 = vals[0], vals[1]
    
    exact_map = {}
    for r in data:
        k = (r["layout"], r["step_id"])
        exact_map.setdefault(k, {})[r["val"]] = r["z"]
        
    Z0, Z1 = [], []
    for k, val_dict in exact_map.items():
        if v0 in val_dict and v1 in val_dict:
            Z0.append(val_dict[v0])
            Z1.append(val_dict[v1])

    if len(Z0) < 10: 
        return sens, dec, 0.0
        
    Z0 = np.stack(Z0)
    Z1 = np.stack(Z1)
    
    idx = np.arange(len(Z0))
    np.random.shuffle(idx)
    split = int(0.8 * len(Z0))
    train_idx, test_idx = idx[:split], idx[split:]

    mapper = nn.Linear(Z0.shape[1], Z1.shape[1])
    opt = optim.Adam(mapper.parameters(), lr=1e-2)
    for _ in range(300):
        pred = mapper(torch.from_numpy(Z0[train_idx]).float())
        loss = ((pred - torch.from_numpy(Z1[train_idx]).float()) ** 2).mean()
        opt.zero_grad()
        loss.backward()
        opt.step()

    with torch.no_grad():
        preds = mapper(torch.from_numpy(Z0[test_idx]).float()).numpy()
    
    target = Z1[test_idx]
    ss_res = float(((target - preds) ** 2).sum())
    ss_tot = float(((target - target.mean(axis=0)) ** 2).sum() + 1e-8)
    r2 = 1.0 - ss_res / ss_tot
    morph = float(max(r2, -1.0))
    
    return sens, dec, morph


def run_gauge_analysis(target_configs=None):
    if target_configs is None:
        target_configs = COMPLEXITIES

    print(f"Searching for checkpoints in {PRETRAIN_CHECKPOINT_DIR}...")
    gauge_types = ["rotation", "step_size", "reward_map", "nuisance", "dist_to_wall"]

    for (hs, nl) in target_configs:
        run_name = f"hs{hs}_l{nl}"
        run_dir = os.path.join(PRETRAIN_CHECKPOINT_DIR, run_name)

        ckpts = glob.glob(os.path.join(run_dir, "*.pt"))
        if not ckpts:
            print(f"Skipping {run_name} (no checkpoints)")
            continue

        final_ckpt = os.path.join(run_dir, "final_solved.pt")
        if os.path.exists(final_ckpt):
            ckpt_path = final_ckpt
        else:
            ckpt_path = max(ckpts, key=os.path.getctime)

        print(f"\nAnalyzing {run_name} from {ckpt_path} ...")

        base_env = HallOfMirrorsGridworld(random_rot=False, random_step=False, random_val=False)
        env = ManualFrameStack(base_env)
        agent = PPOAgent(env, hidden_size=hs, n_hidden_layers=nl)
        agent.load_checkpoint(ckpt_path)

        records = collect_gauge_dataset(agent)
        run_results = []

        for g_type in gauge_types:
            sens, dec, morph = compute_metrics(records, g_type)
            print(f"  > {g_type:12s} | S: {sens:.3f} | D: {dec:.3f} | M: {morph:.3f}")

            run_results.append({
                "hidden_size": hs,
                "num_layers": nl,
                "gauge_type": g_type,
                "sensitivity": sens,
                "decodability": dec,
                "morphism": morph,
            })

        if run_results:
            outfile = os.path.join(PRETRAIN_DATA_DIR, f"gauge_analysis_{run_name}.csv")
            df = pd.DataFrame(run_results)
            df.to_csv(outfile, index=False)
            print(f"Saved analysis to {outfile}")

if __name__ == "__main__":
    run_gauge_analysis()
```

## File: pretrain\main.py

```py
# ============================================
# File: pretrain/main.py
# ============================================

import os
import pandas as pd
import matplotlib.pyplot as plt

from shared.config import (
    COMPLEXITIES,
    PRETRAIN_MAX_STEPS,
    PRETRAIN_TARGET_RETURN,
    PRETRAIN_CHECKPOINT_DIR,
    PRETRAIN_DATA_DIR,
)
from shared.env import HallOfMirrorsGridworld, ManualFrameStack
from shared.agent import PPOAgent, PPOConfig


def run_batch_experiment(target_configs=None):
    if target_configs is None:
        target_configs = COMPLEXITIES

    for (hs, nl) in target_configs:
        run_name = f"hs{hs}_l{nl}"
        print(f"\n--- Running Pretrain Configuration: {run_name} ---")

        # 1. Setup env + agent
        # FIX: Updated to new API (random_rot, etc.)
        base_env = HallOfMirrorsGridworld(
            random_rot=False, 
            random_step=False, 
            random_val=False,
            fixed_sensor_rotation=0, 
            fixed_step_size=1, 
            fixed_good_is_red=False
        )
        env = ManualFrameStack(base_env)
        
        cfg = PPOConfig(total_steps=PRETRAIN_MAX_STEPS, lr=2.5e-4)
        
        agent = PPOAgent(env, hidden_size=hs, n_hidden_layers=nl, config=cfg)

        run_ckpt_dir = os.path.join(PRETRAIN_CHECKPOINT_DIR, run_name)
        os.makedirs(run_ckpt_dir, exist_ok=True)

        # 2. Plot callback
        def plot_cb(stats):
            if not stats:
                return
            df = pd.DataFrame(stats)
            plt.figure(figsize=(10, 6))
            plt.plot(df["step"], df["instant_return"], label="Instant", alpha=0.3)
            plt.plot(df["step"], df["rolling_return"], label="Rolling (20)", linewidth=2)
            plt.xlabel("Steps")
            plt.ylabel("Average Return")
            plt.title(f"Training Progress: {run_name}")
            plt.grid(True)
            plt.legend()
            plt.tight_layout()
            plot_path = os.path.join(run_ckpt_dir, "training_progress.png")
            plt.savefig(plot_path)
            plt.close()

            csv_path = os.path.join(PRETRAIN_DATA_DIR, f"{run_name}_progress.csv")
            df.to_csv(csv_path, index=False)

        # 3. Train
        agent.train(
            stop_at_return=PRETRAIN_TARGET_RETURN,
            checkpoint_dir=run_ckpt_dir,
            plot_callback=plot_cb,
        )


if __name__ == "__main__":
    run_batch_experiment()
```

## File: requirements.txt

```txt
cloudpickle==3.1.2
contourpy==1.3.3
cycler==0.12.1
Farama-Notifications==0.0.4
filelock==3.20.0
fonttools==4.60.1
fsspec==2025.10.0
gymnasium==1.2.2
Jinja2==3.1.6
kiwisolver==1.4.9
MarkupSafe==3.0.3
matplotlib==3.10.7
mpmath==1.3.0
networkx==3.6
numpy==2.3.5
packaging==25.0
pandas==2.3.3
pillow==12.0.0
pyparsing==3.2.5
python-dateutil==2.9.0.post0
pytz==2025.2
setuptools==80.9.0
six==1.17.0
sympy==1.14.0
torch==2.9.1
typing_extensions==4.15.0
tzdata==2025.2
wheel==0.45.1

```

## File: run_pipeline.py

```py
# ============================================
# File: run_pipeline.py
# ============================================

import argparse
import time
from typing import List, Tuple

from shared.config import COMPLEXITIES
from pretrain.main import run_batch_experiment as run_pretrain_batch
from pretrain.gauges import run_gauge_analysis
from mirrors.main import run_batch_mirrors


def main():
    parser = argparse.ArgumentParser(
        description="Run pretraining, gauge analysis, and mirrors adaptation."
    )

    # Parallelization Arguments
    parser.add_argument("--hs", type=int, default=None, help="Hidden Size override")
    parser.add_argument("--layers", type=int, default=None, help="Layers override")

    # Phase Switches
    parser.add_argument("--skip-pretrain", action="store_true", help="Skip pretraining.")
    parser.add_argument("--skip-gauges", action="store_true", help="Skip gauge analysis.")
    parser.add_argument("--skip-mirrors", action="store_true", help="Skip mirrors adaptation.")
    parser.add_argument(
        "--include-unsolved-mirrors",
        action="store_true",
        help="Run mirrors for agents that did not reach PRETRAIN_TARGET_RETURN.",
    )

    args = parser.parse_args()

    # Determine which configs to run
    target_configs: List[Tuple[int, int]] = []
    if args.hs is not None and args.layers is not None:
        target_configs = [(args.hs, args.layers)]
        print(f"Running SINGLE process mode: HS={args.hs}, Layers={args.layers}")
    else:
        target_configs = COMPLEXITIES
        print(f"Running BATCH mode: {len(target_configs)} configurations.")

    t0 = time.time()

    # -------------------------
    # 1. Pretrain
    # -------------------------
    if not args.skip_pretrain:
        print("\n==============================")
        print("  PHASE 1: PRETRAINING")
        print("==============================")
        run_pretrain_batch(target_configs)
    else:
        print("\n[Pipeline] Skipping pretraining phase (--skip-pretrain).")

    # -------------------------
    # 2. Gauge identification
    # -------------------------
    if not args.skip_gauges:
        print("\n==============================")
        print("  PHASE 2: GAUGE IDENTIFICATION")
        print("==============================")
        run_gauge_analysis(target_configs)
    else:
        print("\n[Pipeline] Skipping gauge phase (--skip-gauges).")

    # -------------------------
    # 3. Mirrors adaptation
    # -------------------------
    if not args.skip_mirrors:
        print("\n==============================")
        print("  PHASE 3: HALL-OF-MIRRORS ADAPTATION")
        print("==============================")
        run_batch_mirrors(
            include_unsolved=args.include_unsolved_mirrors,
            target_configs=target_configs
        )
    else:
        print("\n[Pipeline] Skipping mirrors phase (--skip-mirrors).")

    t1 = time.time()
    print("\n==============================")
    print("  PIPELINE COMPLETE")
    print("==============================")
    print(f"Total wall-clock time: {t1 - t0:.1f} seconds.")


if __name__ == "__main__":
    main()
```

## File: shared\agent.py

```py
# ============================================
# File: shared/agent.py
# ============================================

import torch
import torch.optim as optim
import torch.nn as nn
import numpy as np
from collections import deque
from dataclasses import dataclass
from typing import Optional, Callable
import os

from .config import PLOT_INTERVAL, CHECKPOINT_INTERVAL
from .model import ActorCriticNet


@dataclass
class PPOConfig:
    total_steps: int = 200_000
    update_steps: int = 2048
    minibatch_size: int = 256
    ppo_epochs: int = 4
    gamma: float = 0.99
    gae_lambda: float = 0.95
    clip_eps: float = 0.2
    lr: float = 3e-4
    vf_coef: float = 0.5
    ent_coef: float = 0.01
    max_grad_norm: float = 0.5
    device: str = "cuda" if torch.cuda.is_available() else "cpu"


class PPOAgent:
    def __init__(self, env, hidden_size=64, n_hidden_layers=1, config=PPOConfig()):
        self.env = env
        self.config = config
        self.hidden_size = hidden_size
        self.n_hidden_layers = n_hidden_layers

        self.device = config.device
        self.net = ActorCriticNet(
            env.observation_space.shape, env.action_space.n, hidden_size, n_hidden_layers
        ).to(self.device)
        self.optimizer = optim.Adam(self.net.parameters(), lr=config.lr)
        self.total_env_steps = 0

    # --------------------------
    # I/O Helpers
    # --------------------------
    def load_checkpoint(self, path):
        ckpt = torch.load(path, map_location=self.device, weights_only=False)
        self.net.load_state_dict(ckpt["model_state_dict"])
        if "optimizer_state_dict" in ckpt:
            self.optimizer.load_state_dict(ckpt["optimizer_state_dict"])
        self.total_env_steps = ckpt.get("total_env_steps", 0)
        print(f"Loaded checkpoint from {path}")

    def save_checkpoint(self, path):
        torch.save(
            {
                "model_state_dict": self.net.state_dict(),
                "optimizer_state_dict": self.optimizer.state_dict(),
                "total_env_steps": self.total_env_steps,
                "config": self.config,
                "hidden_size": self.hidden_size,
                "n_hidden_layers": self.n_hidden_layers,
            },
            path,
        )

    def get_latent(self, obs_np, prev_reward_val=0.0):
        # Helper for analysis
        obs_t = torch.from_numpy(obs_np).float().to(self.device)
        pr_t = torch.tensor([[prev_reward_val]], dtype=torch.float32).to(self.device)
        with torch.no_grad():
            _, _, z = self.net(obs_t, pr_t)
        return z.cpu().numpy()

    def select_action(self, obs, prev_reward):
        obs_t = torch.from_numpy(obs).float().unsqueeze(0).to(self.device)
        pr_t = torch.tensor([[prev_reward]], dtype=torch.float32).to(self.device)
        with torch.no_grad():
            logits, val, _ = self.net(obs_t, pr_t)
            dist = torch.distributions.Categorical(logits=logits)
            action = dist.sample()
            logprob = dist.log_prob(action)
        return int(action.item()), float(logprob.item()), float(val.item())

    # --------------------------
    # PPO Training Loop
    # --------------------------
    def train(
        self,
        verbose: bool = True,
        stop_at_return: Optional[float] = None,
        checkpoint_dir: Optional[str] = None,
        plot_callback: Optional[Callable] = None,
    ):
        cfg = self.config
        step = self.total_env_steps

        # Initial Reset
        obs, _ = self.env.reset()
        obs = obs.astype(np.float32)
        prev_reward = 0.0

        # Buffers now include prev_rewards (pr_b)
        obs_b, pr_b, act_b, lp_b, rew_b, done_b, val_b = [], [], [], [], [], [], []

        return_hist = deque(maxlen=20)
        training_stats = []

        next_plot = (step // PLOT_INTERVAL + 1) * PLOT_INTERVAL
        next_ckpt = (step // CHECKPOINT_INTERVAL + 1) * CHECKPOINT_INTERVAL

        while step < cfg.total_steps:
            # 1. ROLLOUT
            for _ in range(cfg.update_steps):
                action, lp, val = self.select_action(obs, prev_reward)
                next_obs, reward, terminated, truncated, _ = self.env.step(action)
                done = terminated or truncated

                obs_b.append(obs)
                pr_b.append(prev_reward) # Store input PR
                act_b.append(action)
                lp_b.append(lp)
                rew_b.append(reward)
                done_b.append(done)
                val_b.append(val)

                obs = next_obs.astype(np.float32)
                prev_reward = float(reward)
                step += 1

                if done:
                    obs, _ = self.env.reset()
                    obs = obs.astype(np.float32)
                    prev_reward = 0.0

                if step >= cfg.total_steps:
                    break

            # 2. CALCULATION
            with torch.no_grad():
                # Value of NEXT state
                obs_t = torch.from_numpy(obs).float().unsqueeze(0).to(self.device)
                pr_t = torch.tensor([[prev_reward]], dtype=torch.float32).to(self.device)
                _, last_val, _ = self.net(obs_t, pr_t)
                last_val = float(last_val.item())

            T_rew = torch.tensor(rew_b, dtype=torch.float32, device=self.device)
            T_val = torch.tensor(val_b, dtype=torch.float32, device=self.device)
            T_done = torch.tensor(done_b, dtype=torch.float32, device=self.device)

            advs = []
            gae = 0.0
            for i in reversed(range(len(rew_b))):
                mask = 1.0 - T_done[i].item()
                next_val = last_val if i == len(rew_b) - 1 else T_val[i + 1].item()
                delta = (
                    T_rew[i].item()
                    + cfg.gamma * next_val * mask
                    - T_val[i].item()
                )
                gae = delta + cfg.gamma * cfg.gae_lambda * mask * gae
                advs.insert(0, gae)

            T_obs = torch.tensor(np.array(obs_b), dtype=torch.float32, device=self.device)
            T_pr = torch.tensor(np.array(pr_b), dtype=torch.float32, device=self.device).unsqueeze(1)
            T_act = torch.tensor(act_b, dtype=torch.long, device=self.device)
            T_lp = torch.tensor(lp_b, dtype=torch.float32, device=self.device)
            T_adv = torch.tensor(advs, dtype=torch.float32, device=self.device)
            T_ret = T_adv + T_val

            T_adv = (T_adv - T_adv.mean()) / (T_adv.std() + 1e-8)

            dataset_size = len(obs_b)
            idxs = np.arange(dataset_size)

            # 3. OPTIMIZATION
            for _ in range(cfg.ppo_epochs):
                np.random.shuffle(idxs)
                for start in range(0, dataset_size, cfg.minibatch_size):
                    end = start + cfg.minibatch_size
                    b_idx = idxs[start:end]
                    
                    # Forward pass with OBS and PREV_REWARD
                    logits, v, _ = self.net(T_obs[b_idx], T_pr[b_idx])
                    
                    dist = torch.distributions.Categorical(logits=logits)
                    new_lp = dist.log_prob(T_act[b_idx])
                    entropy = dist.entropy().mean()

                    ratio = (new_lp - T_lp[b_idx]).exp()
                    surr1 = ratio * T_adv[b_idx]
                    surr2 = torch.clamp(
                        ratio, 1.0 - cfg.clip_eps, 1.0 + cfg.clip_eps
                    ) * T_adv[b_idx]

                    policy_loss = -torch.min(surr1, surr2).mean()
                    value_loss = (T_ret[b_idx] - v.squeeze(-1)).pow(2).mean()
                    loss = policy_loss + cfg.vf_coef * value_loss - cfg.ent_coef * entropy

                    self.optimizer.zero_grad()
                    loss.backward()
                    nn.utils.clip_grad_norm_(self.net.parameters(), cfg.max_grad_norm)
                    self.optimizer.step()

            # Clear buffers
            obs_b.clear(); pr_b.clear(); act_b.clear(); lp_b.clear()
            rew_b.clear(); done_b.clear(); val_b.clear()

            self.total_env_steps = step

            # 4. MAINTENANCE
            if step >= next_plot or step >= cfg.total_steps:
                avg_ret = evaluate_agent(self, self.env, n_episodes=10)
                
                # CRITICAL: Reset env after eval to sync state
                obs, _ = self.env.reset()
                obs = obs.astype(np.float32)
                prev_reward = 0.0

                return_hist.append(avg_ret)
                rolling = float(np.mean(return_hist))

                stats_entry = {
                    "step": step,
                    "instant_return": avg_ret,
                    "rolling_return": rolling,
                }
                training_stats.append(stats_entry)

                if verbose:
                    print(
                        f"  Step {step} | Instant: {avg_ret:.2f} | Rolling: {rolling:.2f}"
                    )

                if plot_callback:
                    plot_callback(training_stats)

                if (
                    stop_at_return is not None
                    and len(return_hist) >= 10
                    and rolling >= stop_at_return
                ):
                    print(
                        f"  -> Solved! Reached {stop_at_return:.2f} (Rolling: {rolling:.2f})"
                    )
                    if checkpoint_dir:
                        self.save_checkpoint(
                            os.path.join(checkpoint_dir, "final_solved.pt")
                        )
                    break

                while next_plot <= step:
                    next_plot += PLOT_INTERVAL

            if checkpoint_dir and step >= next_ckpt:
                filename = f"ckpt_step_{step}.pt"
                self.save_checkpoint(os.path.join(checkpoint_dir, filename))
                while next_ckpt <= step:
                    next_ckpt += CHECKPOINT_INTERVAL

        return training_stats


def evaluate_agent(agent: PPOAgent, env, n_episodes=20) -> float:
    total = 0.0
    for _ in range(n_episodes):
        obs, _ = env.reset()
        obs = obs.astype(np.float32)
        prev_reward = 0.0
        done = False
        ep_ret = 0.0
        while not done:
            action, _, _ = agent.select_action(obs, prev_reward)
            obs, r, term, trunc, _ = env.step(action)
            obs = obs.astype(np.float32)
            prev_reward = float(r)
            ep_ret += r
            done = term or trunc
        total += ep_ret
    return total / n_episodes
```

## File: shared\config.py

```py
# ============================================
# File: shared/config.py
# ============================================

from typing import List, Tuple
import os

# --------------------------
# World / Environment
# --------------------------
GRID_SIZE = 8
MAX_STEPS_PER_EPISODE = 100
FRAME_STACK_SIZE = 4
N_GOOD_TILES = 20
N_BAD_TILES = 20

# Rewards
GOOD_TILE_REWARD = 1.0
BAD_TILE_PENALTY = -0.5
WALL_PENALTY = -0.05
STEP_PENALTY = -0.01

# --------------------------
# Logging / Checkpoints
# --------------------------
PLOT_INTERVAL = 2048
CHECKPOINT_INTERVAL = 500_000 # Change for mock

# --------------------------
# Architectures
# --------------------------
COMPLEXITIES: List[Tuple[int, int]] = [
    (8, 1), (16, 1), (32, 1), (64, 1), (128, 1), (256, 1), (512, 1), (1024, 1),
    (8, 2), (16, 2), (32, 2), (64, 2), (128, 2), (256, 2), (512, 2), (1024, 2),
    (8, 3), (16, 3), (32, 3), (64, 3), (128, 3), (256, 3), (512, 3), (1024, 3),
]

# --------------------------
# Training Budgets
# --------------------------
PRETRAIN_MAX_STEPS = 6_000_000 # Change for mock
PRETRAIN_TARGET_RETURN = 12 # Change for mock

GRACE_STEPS = 100_000 # Change for mock
HALL_STEPS = 6_000_000 # Change for mock
STAGE_BUDGET = 2_000_000 # Change for mock

# --------------------------
# Paths
# --------------------------

# Specific downloaded results
DOWNLOAD_ROOT = os.path.join("downloaded_results", "2025-11-28_18-21-38")
PRETRAIN_CHECKPOINT_DIR = os.path.join(DOWNLOAD_ROOT, "pretrain", "checkpoints")
PRETRAIN_DATA_DIR = os.path.join(DOWNLOAD_ROOT, "pretrain", "data")
MIRRORS_CHECKPOINT_DIR = os.path.join(DOWNLOAD_ROOT, "mirrors", "checkpoints")
MIRRORS_DATA_DIR = os.path.join(DOWNLOAD_ROOT, "mirrors", "data")

# Create new results
# PRETRAIN_CHECKPOINT_DIR = os.path.join("pretrain", "checkpoints")
# PRETRAIN_DATA_DIR = os.path.join("pretrain", "data")
# MIRRORS_CHECKPOINT_DIR = os.path.join("mirrors", "checkpoints")
# MIRRORS_DATA_DIR = os.path.join("mirrors", "data")
# for d in [
#     PRETRAIN_CHECKPOINT_DIR,
#     PRETRAIN_DATA_DIR,
#     MIRRORS_CHECKPOINT_DIR,
#     MIRRORS_DATA_DIR,
# ]:
#     os.makedirs(d, exist_ok=True)
```

## File: shared\env.py

```py
# ============================================
# File: shared/env.py
# ============================================

import numpy as np
import gymnasium as gym
from gymnasium import spaces
from collections import deque
from .config import (
    GRID_SIZE,
    MAX_STEPS_PER_EPISODE,
    N_GOOD_TILES,
    N_BAD_TILES,
    GOOD_TILE_REWARD,
    BAD_TILE_PENALTY,
    WALL_PENALTY,
    STEP_PENALTY,
    FRAME_STACK_SIZE,
)


class ManualFrameStack(gym.Wrapper):
    def __init__(self, env, num_stack=FRAME_STACK_SIZE):
        super().__init__(env)
        self.num_stack = num_stack
        self.frames = deque(maxlen=num_stack)
        c, h, w = env.observation_space.shape
        self.observation_space = spaces.Box(
            low=0.0,
            high=1.0,
            shape=(c * num_stack, h, w),
            dtype=env.observation_space.dtype,
        )

    def reset(self, **kwargs):
        obs, info = self.env.reset(**kwargs)
        for _ in range(self.num_stack):
            self.frames.append(obs)
        return self._get_ob(), info

    def step(self, action):
        obs, reward, terminated, truncated, info = self.env.step(action)
        self.frames.append(obs)
        return self._get_ob(), reward, terminated, truncated, info

    def _get_ob(self):
        return np.concatenate(list(self.frames), axis=0)


class HallOfMirrorsGridworld(gym.Env):
    metadata = {"render_modes": ["human"]}

    def __init__(
        self,
        grid_size=GRID_SIZE,
        max_steps=MAX_STEPS_PER_EPISODE,
        n_good_tiles=N_GOOD_TILES,
        n_bad_tiles=N_BAD_TILES,
        seed=0,
        # Granular Randomization Flags
        random_rot=False,
        random_step=False,
        random_val=False,
        # Fixed Defaults
        fixed_sensor_rotation=0,
        fixed_step_size=1,
        fixed_good_is_red=False,
    ):
        super().__init__()
        self.grid_size = grid_size
        self.max_steps = max_steps
        self.n_good_tiles = n_good_tiles
        self.n_bad_tiles = n_bad_tiles
        self._np_seed = seed
        self.rng = np.random.RandomState(seed)

        # Config
        self.random_rot = random_rot
        self.random_step = random_step
        self.random_val = random_val
        
        self.fixed_sensor_rotation = fixed_sensor_rotation
        self.fixed_step_size = fixed_step_size
        self.fixed_good_is_red = fixed_good_is_red

        self.action_space = spaces.Discrete(4)
        self.observation_space = spaces.Box(
            low=0.0,
            high=1.0,
            shape=(5, grid_size, grid_size),
            dtype=np.float32,
        )

        self.grid = None
        self.agent_pos = None
        self.steps = 0
        self.sensor_rotation = 0
        self.step_size = 1
        self.good_is_red = False
        self.irrelevant_pattern = None
        self.collected = None

    def reseed(self, seed: int):
        self._np_seed = seed
        self.rng = np.random.RandomState(seed)

    def _sample_gauges(self):
        # 1. Rotation
        if self.random_rot:
            self.sensor_rotation = int(self.rng.choice([0, 1, 2, 3]))
        else:
            self.sensor_rotation = int(self.fixed_sensor_rotation)
            
        # 2. Step Size
        if self.random_step:
            self.step_size = int(self.rng.choice([1, 2]))
        else:
            self.step_size = int(self.fixed_step_size)
            
        # 3. Value Map
        if self.random_val:
            self.good_is_red = bool(self.rng.choice([0, 1]))
        else:
            self.good_is_red = bool(self.fixed_good_is_red)

        self.irrelevant_pattern = self.rng.rand(self.grid_size, self.grid_size).astype(
            np.float32
        )

    def _generate_layout(self):
        g = np.zeros((self.grid_size, self.grid_size), dtype=np.int32)
        for _ in range(self.grid_size * 2):
            y = self.rng.randint(0, self.grid_size)
            x = self.rng.randint(0, self.grid_size)
            g[y, x] = 1  # walls

        empty = list(zip(*np.where(g == 0)))
        self.rng.shuffle(empty)

        n_avail = max(0, len(empty) - 1)
        n_g = min(self.n_good_tiles, n_avail)
        n_b = min(self.n_bad_tiles, n_avail - n_g)

        count = 0
        for y, x in empty:
            if count < n_g:
                g[y, x] = 2
            elif count < n_g + n_b:
                g[y, x] = 3
            else:
                break
            count += 1

        empty = list(zip(*np.where(g == 0)))
        if not empty:
            cy = self.grid_size // 2
            cx = self.grid_size // 2
            g[cy, cx] = 0
            empty = [(cy, cx)]
        self.agent_pos = list(empty[self.rng.randint(0, len(empty))])
        self.grid = g
        self.collected = np.zeros_like(g, dtype=bool)

    def reset(self, seed=None, options=None):
        if seed is not None:
            self.reseed(seed)
        self.steps = 0
        self._sample_gauges()
        self._generate_layout()
        return self._get_obs(), {}

    def _rotate_obs(self, obs):
        k = self.sensor_rotation
        if k == 0:
            return obs
        obs_hw_c = np.transpose(obs, (1, 2, 0))
        obs_rot = np.rot90(obs_hw_c, k=k, axes=(0, 1))
        return np.transpose(obs_rot, (2, 0, 1))

    def _get_obs(self):
        wall = (self.grid == 1).astype(np.float32)
        red = (self.grid == 2).astype(np.float32)
        blue = (self.grid == 3).astype(np.float32)
        agent = np.zeros_like(wall, dtype=np.float32)
        ay, ax = self.agent_pos
        agent[ay, ax] = 1.0
        obs = np.stack([wall, red, blue, agent, self.irrelevant_pattern], axis=0)
        return self._rotate_obs(obs)

    def step(self, action):
        self.steps += 1
        reward = 0.0

        dy, dx = {0: (-1, 0), 1: (0, 1), 2: (1, 0), 3: (0, -1)}[action]

        for _ in range(self.step_size):
            ny = self.agent_pos[0] + dy
            nx = self.agent_pos[1] + dx
            if (
                0 <= ny < self.grid_size
                and 0 <= nx < self.grid_size
                and self.grid[ny, nx] != 1
            ):
                self.agent_pos = [ny, nx]
            else:
                reward += WALL_PENALTY
                break

        ay, ax = self.agent_pos
        if self.grid[ay, ax] in (2, 3) and not self.collected[ay, ax]:
            self.collected[ay, ax] = True
            is_red = self.grid[ay, ax] == 2
            if self.good_is_red:
                tile_reward = GOOD_TILE_REWARD if is_red else BAD_TILE_PENALTY
            else:
                tile_reward = BAD_TILE_PENALTY if is_red else GOOD_TILE_REWARD
            reward += tile_reward

            self.grid[ay, ax] = 0

        reward += STEP_PENALTY
        truncated = self.steps >= self.max_steps
        terminated = False
        return self._get_obs(), reward, terminated, truncated, {}
    
    def force_noise_pattern(self, seed: int):
        """For analysis only: overrides the noise channel."""
        rng = np.random.RandomState(seed)
        self.irrelevant_pattern = rng.rand(self.grid_size, self.grid_size).astype(
            np.float32
        )
```

## File: shared\model.py

```py
# ============================================
# File: shared/model.py
# ============================================

import torch
import torch.nn as nn


class ActorCriticNet(nn.Module):
    def __init__(self, obs_shape, n_actions, hidden_size=64, n_hidden_layers=1):
        super().__init__()
        c, h, w = obs_shape
        self.conv = nn.Sequential(
            nn.Conv2d(c, 16, 3, 1, 1),
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, 1, 1),
            nn.ReLU(),
            nn.Flatten(),
        )
        with torch.no_grad():
            conv_out = self.conv(torch.zeros(1, c, h, w)).shape[1]

        layers = []
        # Input dim is conv_out + 1 (for prev_reward)
        in_dim = conv_out + 1 
        for _ in range(n_hidden_layers):
            layers.append(nn.Linear(in_dim, hidden_size))
            layers.append(nn.ReLU())
            in_dim = hidden_size

        self.mlp = nn.Sequential(*layers) if layers else nn.Identity()
        latent_dim = hidden_size if layers else in_dim

        self.actor = nn.Linear(latent_dim, n_actions)
        self.critic = nn.Linear(latent_dim, 1)

    def forward(self, x, prev_reward):
        # x: [B, C, H, W]
        # prev_reward: [B, 1]
        z_img = self.conv(x)
        
        # Fuse image features with previous reward
        z_combined = torch.cat([z_img, prev_reward], dim=1)
        
        z = self.mlp(z_combined)
        logits = self.actor(z)
        value = self.critic(z)
        return logits, value, z
```

## File: utils\gcp\config.py

```py
import os

# ====================================================
# GCP CONFIGURATION
# ====================================================

VM_NAME = "mirrors-experiment-01"
ZONE = "us-central1-f"  # Ensure this matches your VM's zone
REMOTE_DIR = "gauges_experiment" # Where code lives on the VM

# Local folder where we save downloaded results
LOCAL_RESULTS_DIR = os.path.join(os.path.dirname(__file__), "..", "..", "downloaded_results")

# Port for the view.py visualization
PORT = 8080

# Patterns to ignore when Zipping code for deployment
IGNORE_PATTERNS = [
    "__pycache__",
    "*.git*",
    "*.vscode*",
    "venv",
    "env",
    "logs",
    "downloaded_results",
    "deploy.zip",
    "*.DS_Store",
    "utils/gcp"
]
```

## File: utils\gcp\connect.py

```py
import subprocess
from .config import VM_NAME, ZONE

def connect():
    print(f"🔌 SSH Connecting to {VM_NAME}...")
    print("   (Type 'exit' to disconnect)")

    # Construct the command
    cmd = f"gcloud compute ssh {VM_NAME} --zone={ZONE}"

    try:
        # shell=True allows the SSH session to take over the terminal window interactively
        subprocess.run(cmd, shell=True)
    except KeyboardInterrupt:
        print("\nDisconnected.")

if __name__ == "__main__":
    connect()
```

## File: utils\gcp\pull_data.py

```py
import os
import subprocess
import datetime
import sys
from .config import VM_NAME, ZONE, REMOTE_DIR, LOCAL_RESULTS_DIR

def pull_data():
    # 1. Create Timestamped Folder
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    dest_dir = os.path.join(LOCAL_RESULTS_DIR, timestamp)
    os.makedirs(dest_dir, exist_ok=True)

    print(f"📥 Pulling data from {VM_NAME}...")
    print(f"📂 Destination: {dest_dir}")

    # 2. Define remote paths to grab
    # We grab the parent 'data' and 'checkpoints' folders for both phases
    targets = [
        f"{REMOTE_DIR}/pretrain/data",
        f"{REMOTE_DIR}/pretrain/checkpoints",
        f"{REMOTE_DIR}/mirrors/data",
        f"{REMOTE_DIR}/mirrors/checkpoints",
    ]

    # 3. Execute SCP commands
    for target in targets:
        # Determine local subdirectory structure
        # e.g. pretrain/data -> dest_dir/pretrain/data
        rel_path = target.replace(f"{REMOTE_DIR}/", "")
        local_target_path = os.path.join(dest_dir, os.path.dirname(rel_path))
        os.makedirs(local_target_path, exist_ok=True)

        cmd = [
            "gcloud", "compute", "scp",
            "--recurse",
            "--zone", ZONE,
            f"{VM_NAME}:{target}",
            local_target_path
        ]

        print(f"   Downloading: {rel_path}...")
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode != 0:
            # It's common to fail if the folder doesn't exist yet on remote (e.g. no mirrors run yet)
            print(f"   ⚠️  Skipped (not found or empty): {rel_path}")
        else:
            print(f"   ✅ Success")

    print("\n✨ Download Complete!")
    print(f"   Explorer: {os.path.abspath(dest_dir)}")

if __name__ == "__main__":
    pull_data()
```

## File: utils\gcp\push_code.py

```py
import os
import zipfile
import subprocess
import fnmatch
from .config import VM_NAME, ZONE, REMOTE_DIR, IGNORE_PATTERNS

def get_project_root():
    return os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))

def should_ignore(path, root):
    rel_path = os.path.relpath(path, root)
    for part in rel_path.split(os.sep):
        for pattern in IGNORE_PATTERNS:
            if fnmatch.fnmatch(part, pattern):
                return True
    filename = os.path.basename(path)
    for pattern in IGNORE_PATTERNS:
        if fnmatch.fnmatch(filename, pattern):
            return True
    return False

def zip_project(zip_name="deploy.zip"):
    root = get_project_root()
    zip_path = os.path.join(root, zip_name)
    print(f"📦 Zipping project at {root}...")
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for folder, _, files in os.walk(root):
            for file in files:
                full_path = os.path.join(folder, file)
                if should_ignore(full_path, root):
                    continue
                if file == zip_name:
                    continue
                rel_path = os.path.relpath(full_path, root)
                zipf.write(full_path, rel_path)
    return zip_path

def push_code():
    zip_path = zip_project()
    zip_filename = os.path.basename(zip_path)

    # 1. Clean Remote
    print(f"🧹 Force-cleaning remote directory: {REMOTE_DIR}...")
    remote_prep_cmd = (
        "sudo pkill -f python; "           
        f"sudo rm -rf {REMOTE_DIR}"        
    )
    subprocess.run([
        "gcloud", "compute", "ssh", VM_NAME,
        "--zone", ZONE,
        "--command", remote_prep_cmd
    ], shell=True) 

    # 2. Upload Zip
    print(f"rw Sending {zip_filename} to VM Home...")
    upload_cmd = [
        "gcloud", "compute", "scp",
        zip_path,
        f"{VM_NAME}:.",   
        "--zone", ZONE
    ]
    subprocess.run(upload_cmd, shell=True, check=True)

    # 3. Unzip, Install, Fix Permissions
    print("📂 Unzipping and installing requirements...")
    
    # THE FIX: Added --break-system-packages to the pip install command
    install_cmd = (
        f"sudo unzip -o {zip_filename} -d {REMOTE_DIR} && "
        f"sudo chown -R $USER:$USER {REMOTE_DIR} && "
        f"chmod +x {REMOTE_DIR}/launch_parallel.sh && "
        f"cd {REMOTE_DIR} && pip install -r requirements.txt --break-system-packages && "
        f"cd ~ && rm {zip_filename}"
    )

    subprocess.run([
        "gcloud", "compute", "ssh", VM_NAME,
        "--zone", ZONE,
        "--command", install_cmd
    ], shell=True, check=True)

    os.remove(zip_path)
    print("\n🚀 Deployment Complete!")
    print("   You can now run: ./launch_parallel.sh on the VM.")

if __name__ == "__main__":
    push_code()
```

## File: utils\gcp\view.py

```py
import subprocess
import time
import webbrowser
from .config import VM_NAME, ZONE, REMOTE_DIR, PORT

def view_training():
    print(f"🔭 Preparing to view {VM_NAME}...")

    # 1. Start the Remote HTTP Server (Background)
    # We send a command to start the python server using 'nohup' so it keeps running
    print(f"   📡 Restarting remote web server on port {PORT}...")
    start_server_cmd = [
        "gcloud", "compute", "ssh", VM_NAME,
        "--zone", ZONE,
        "--command",
        f"cd {REMOTE_DIR} && nohup python3 -m http.server {PORT} > /dev/null 2>&1 &"
    ]
    subprocess.run(start_server_cmd, shell=True)

    # 2. Establish Tunnel
    print(f"   fw Opening tunnel: Local {PORT} -> Remote {PORT}")
    print("   Press CTRL+C to stop viewing.\n")

    url = f"http://localhost:{PORT}"
    
    # --ssh-flag syntax ensures compatibility with Windows PowerShell
    tunnel_cmd = [
        "gcloud", "compute", "ssh", VM_NAME,
        "--zone", ZONE,
        f"--ssh-flag=-N",
        f"--ssh-flag=-L {PORT}:localhost:{PORT}"
    ]

    try:
        # Launch the tunnel
        proc = subprocess.Popen(tunnel_cmd, shell=True)
        
        # Give the tunnel a moment to shake hands
        time.sleep(3) 
        
        print(f"✅ Active! Opening {url} ...")
        webbrowser.open(url)
        
        # Keep script running until user kills it
        proc.wait()
    except KeyboardInterrupt:
        print("\n🛑 Closing tunnel.")
        proc.terminate()

if __name__ == "__main__":
    view_training()
```

## File: utils\gcp\vm_steps.txt

```txt
<< LOCAL >>

Close any existing VM windows and terminals

# Open Terminal 1
python -m utils.gcp.connect

<< VM >>

sudo pkill -f python
htop
cd ..
sudo rm -rf gauges_experiment
Close any existing VM windows and terminals

<< LOCAL >>

# Open Terminal 1
python -m utils.gcp.push_code
python -m utils.gcp.view

# Open Terminal 2
python -m utils.gcp.view

# Open Terminal 3
python -m utils.gcp.connect

<< VM >>

cd gauges_experiment
ls
./launch_parallel.sh
htop
```

## File: utils\plot_story.py

```py
# ============================================
# File: utils/plot_story.py
# ============================================

import os
import glob
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from shared.config import PRETRAIN_DATA_DIR, MIRRORS_DATA_DIR, PRETRAIN_TARGET_RETURN

OUTPUT_DIR = "analysis_results"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Helper for Gauge Score
def calc_score(row):
    s = row.get('sensitivity', 0)
    m = row.get('morphism', 0)
    d = row.get('decodability', 0)
    # Clip decodability to [0,1]
    d = max(0.0, min(1.0, d))
    # Clip morphism lower bound to 0
    m = max(0.0, m)
    return s * m * (1.0 - d)

def load_all_data():
    # 1. Load Pretrain Gauges (Baseline)
    pre_files = glob.glob(os.path.join(PRETRAIN_DATA_DIR, "gauge_analysis_hs*_l*.csv"))
    df_pre_list = []
    for f in pre_files:
        df = pd.read_csv(f)
        df['phase'] = 'Pretrain'
        df['gauge_score'] = df.apply(calc_score, axis=1)
        df_pre_list.append(df)
    df_pre = pd.concat(df_pre_list, ignore_index=True) if df_pre_list else pd.DataFrame()

    # 2. Load Stage Gauges (Mirrors)
    stage_files = glob.glob(os.path.join(MIRRORS_DATA_DIR, "gauge_analysis_stages_*.csv"))
    df_stage_list = []
    for f in stage_files:
        df = pd.read_csv(f) # has 'stage' column
        df['phase'] = df['stage']
        df['gauge_score'] = df.apply(calc_score, axis=1)
        df_stage_list.append(df)
    df_stage = pd.concat(df_stage_list, ignore_index=True) if df_stage_list else pd.DataFrame()

    # 3. Load Summaries (Performance Recovery)
    sum_files = glob.glob(os.path.join(MIRRORS_DATA_DIR, "mirrors_summary_*.csv"))
    df_sum_list = []
    for f in sum_files:
        df_sum_list.append(pd.read_csv(f))
    df_perf = pd.concat(df_sum_list, ignore_index=True) if df_sum_list else pd.DataFrame()

    # Calculate Params (Approx)
    # params approx = layers * hs^2 + ...
    # We just use hs * layers as a proxy for "Complexity Class" or just plot against HS
    if not df_perf.empty:
        df_perf['params'] = df_perf['hidden_size'] * df_perf['hidden_size'] * df_perf['layers'] # Rough proxy

    return df_pre, df_stage, df_perf

def plot_fig1_baseline(df_pre):
    """
    Fig 1: Baseline gauge identification
    Boxplot of Gauge Score for 5 features.
    Overlay Scatter colored by Hidden Size (Complexity).
    """
    plt.figure(figsize=(10, 6))
    
    # Order: Explicit, Noise, Gauges...
    order = ["dist_to_wall", "nuisance", "rotation", "step_size", "reward_map"]
    
    # Boxplot
    sns.boxplot(data=df_pre, x="gauge_type", y="gauge_score", order=order, color="white", showfliers=False)
    
    # Strip/Swarm plot
    # We use hue to color by size
    sns.stripplot(data=df_pre, x="gauge_type", y="gauge_score", order=order, 
                  hue="hidden_size", palette="viridis", alpha=0.8, jitter=0.2)
    
    plt.title("Figure 1: Baseline Gauge Identification (Pre-Adaptation)")
    plt.ylabel("Gauge Score")
    plt.grid(axis='y', linestyle='--', alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, "fig1_baseline_identification.png"))
    plt.close()

def plot_fig3_grid(df_pre, df_stage, df_perf):
    """
    Fig 3: 3x2 Grid
    Left Col: Performance Recovery vs Complexity
    Right Col: Gauge Reification vs Complexity
    Rows: Rotation, Step, Value
    """
    if df_perf.empty or df_stage.empty: return

    fig, axes = plt.subplots(3, 2, figsize=(12, 12))
    
    # We iterate rows by Feature
    features = [
        ("rotation", "stage_1_rot", "rec_rot"),
        ("step_size", "stage_2_step", "rec_step"),
        ("reward_map", "stage_3_val", "rec_val")
    ]
    
    # Calculate Reification for all points
    # Merge Pre and Stage on (hs, layers, gauge_type)
    # We filter df_stage for the SPECIFIC stage relevant to the gauge
    # e.g. for Rotation, we compare Pre vs Stage_1_Rot
    
    for i, (gauge_name, stage_name, rec_col) in enumerate(features):
        # --- LEFT: Performance Recovery ---
        # Y-axis: rec_col / 12.0 (Baseline 12)
        df_perf['recovery_pct'] = df_perf[rec_col] / PRETRAIN_TARGET_RETURN
        
        ax_perf = axes[i, 0]
        sns.lineplot(data=df_perf, x="hidden_size", y="recovery_pct", hue="layers", 
                     palette="tab10", marker="o", ax=ax_perf)
        ax_perf.set_title(f"Performance Recovery ({gauge_name.capitalize()})")
        ax_perf.set_ylim(0, 1.2)
        ax_perf.set_ylabel("% of Baseline (12.0)")
        
        # --- RIGHT: Gauge Reification ---
        # 1. Get Pre scores for this gauge
        d_pre = df_pre[df_pre['gauge_type'] == gauge_name][['hidden_size', 'layers', 'gauge_score']]
        # 2. Get Post scores (at end of THIS specific stage)
        d_post = df_stage[
            (df_stage['gauge_type'] == gauge_name) & 
            (df_stage['stage'] == stage_name)
        ][['hidden_size', 'layers', 'gauge_score']]
        
        # Merge
        merged = pd.merge(d_pre, d_post, on=['hidden_size', 'layers'], suffixes=('_pre', '_post'))
        merged['reification'] = (merged['gauge_score_pre'] - merged['gauge_score_post'])
        
        ax_reif = axes[i, 1]
        sns.lineplot(data=merged, x="hidden_size", y="reification", hue="layers",
                     palette="tab10", marker="o", ax=ax_reif)
        ax_reif.set_title(f"Gauge Reification ({gauge_name.capitalize()})")
        ax_reif.set_ylabel("Score Drop (Pre - Post)")
        ax_reif.axhline(0, color='black', linewidth=0.5, linestyle='--')

    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, "fig3_grid.png"))
    plt.close()

def generate_table_1(df_pre, df_stage):
    """
    Table 1: Gauge Scores across phases.
    Aggregated across all complexities (Mean ± Std).
    """
    # 1. Pretrain
    summ_pre = df_pre.groupby('gauge_type')['gauge_score'].agg(['mean', 'std'])
    summ_pre.columns = ['Pre_Mean', 'Pre_Std']
    
    # 2. Stage 1
    s1 = df_stage[df_stage['stage'] == 'stage_1_rot']
    summ_s1 = s1.groupby('gauge_type')['gauge_score'].agg(['mean', 'std'])
    summ_s1.columns = ['S1_Mean', 'S1_Std']
    
    # 3. Stage 2
    s2 = df_stage[df_stage['stage'] == 'stage_2_step']
    summ_s2 = s2.groupby('gauge_type')['gauge_score'].agg(['mean', 'std'])
    summ_s2.columns = ['S2_Mean', 'S2_Std']
    
    # 4. Stage 3
    s3 = df_stage[df_stage['stage'] == 'stage_3_val']
    summ_s3 = s3.groupby('gauge_type')['gauge_score'].agg(['mean', 'std'])
    summ_s3.columns = ['S3_Mean', 'S3_Std']
    
    # Join
    full_table = pd.concat([summ_pre, summ_s1, summ_s2, summ_s3], axis=1)
    csv_path = os.path.join(OUTPUT_DIR, "table1_gauge_evolution.csv")
    full_table.to_csv(csv_path)
    print(f"Table 1 saved to {csv_path}")

def main():
    print("Loading Data...")
    df_pre, df_stage, df_perf = load_all_data()
    
    if df_pre.empty:
        print("No data found. Run pipeline first.")
        return

    print("Generating Figure 1...")
    plot_fig1_baseline(df_pre)
    
    print("Generating Figure 3...")
    plot_fig3_grid(df_pre, df_stage, df_perf)
    
    print("Generating Table 1...")
    generate_table_1(df_pre, df_stage)
    
    print("Done.")

if __name__ == "__main__":
    main()
```

